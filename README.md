# üê±‚ö° TurboCat

[üá¨üáß English](#english) | [üá∑üá∫ –†—É—Å—Å–∫–∏–π](#russian)

---

<a name="english"></a>
# üá¨üáß English

**Next-generation gradient boosting that matches CatBoost quality while being 3-10x faster.**

TurboCat is a C++ gradient boosting library with Python bindings, implementing cutting-edge research techniques: GradTree (AAAI 2024), Robust Focal Loss, Tsallis entropy splitting, and GOSS sampling.

[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

---

## üìä Benchmark Results

Tested on 30 datasets (synthetic, imbalanced, non-linear, high-dimensional, real-world):

### Quality: Parity with CatBoost

| Metric | TurboCat | CatBoost | p-value |
|--------|----------|----------|---------|
| Accuracy | 0.9164 | 0.9171 | 0.87 |
| ROC-AUC | 0.9515 | 0.9568 | 0.17 |
| F1 | **0.8786** | 0.8695 | 0.31 |
| Recall | **0.8657** | 0.8592 | 0.45 |

*No statistically significant difference (t-test, Wilcoxon).*

### Performance: TurboCat is Faster

| Metric | TurboCat vs CatBoost |
|--------|---------------------|
| Training | **3.5x faster** (median 1.8x) |
| Inference | **9.7x faster** (median 6.8x) |
| Max speedup | up to **18.9x** training, **33x** inference |

---

## ‚úÖ Strengths

### 1. Imbalanced Data ‚Äî Key Advantage

TurboCat performs significantly better on imbalanced datasets:

| Dataset | Recall TC | Recall CB | F1 TC | F1 CB |
|---------|-----------|-----------|-------|-------|
| 70/30 | **91.2%** | 87.4% | **93.6%** | 91.3% |
| 85/15 | **84.7%** | 75.9% | **89.8%** | 84.7% |
| 95/5 | **54.5%** | 45.5% | **70.2%** | 62.1% |
| 99/1 | **15.8%** | 3.5% | **27.3%** | 6.8% |

On extremely imbalanced data (99/1), TurboCat shows **4x higher F1 score**.

### 2. Speed

- Training: Faster on 23/30 datasets
- Inference: Faster on 30/30 datasets
- Particularly effective on small-medium datasets (up to 20x speedup)

### 3. Medium-Large Scale (5K-50K samples)

- Accuracy: 4/5 wins against CatBoost
- ROC-AUC: 4/5 wins

### 4. Special Cases

- **Highly correlated features**: +0.2% ROC-AUC
- **Data with outliers**: +0.3% ROC-AUC
- **High-dim with many informative features**: +3.2% ROC-AUC

---

## ‚ö†Ô∏è Weaknesses

### 1. Noisy Data

On data with >10% label noise, TurboCat loses up to -9.9% ROC-AUC.

### 2. Small Datasets (<1K samples)

CatBoost generalizes better on small samples (1/4 wins by ROC-AUC).

### 3. High-dimensional Sparse Data

With many irrelevant features (200f, 20 informative), CatBoost is slightly better.

---

## üéØ When to Use

### ‚úÖ Recommended:

- **Fraud detection, medical diagnosis** ‚Äî imbalanced classes
- **Production deployment** ‚Äî inference speed is critical
- **Real-time predictions** ‚Äî up to 33x faster
- **Medium-large datasets** ‚Äî 5K+ samples

### ‚ö†Ô∏è Consider Alternatives:

- Very noisy data (>10% label noise)
- Very small samples (<500 samples)
- Extreme high-dimensional sparse data

---

## üõ† Installation

```bash
git clone https://github.com/ispromadhka/Turbo-Cat.git
cd Turbo-Cat
mkdir build && cd build
cmake .. -DCMAKE_BUILD_TYPE=Release
make -j8
```

### Requirements

- C++17 compiler (GCC 10+, Clang 12+, Apple Clang 14+)
- CMake 3.18+
- Python 3.8+
- NumPy

### Optional dependencies

- OpenMP (for parallel training)
- Eigen3 (auto-downloaded if not found)

---

## üî• Quick Start

```python
import sys
sys.path.insert(0, 'build')
import _turbocat as tc
import numpy as np

# Create classifier
model = tc.TurboCatClassifier(
    n_estimators=50,
    max_depth=8,
    learning_rate=0.1,
    verbosity=0
)

# Train
model.fit(X_train.astype(np.float32), y_train.astype(np.float32))

# Predict
proba = np.array(model.predict_proba(X_test.astype(np.float32)))
predictions = (proba > 0.5).astype(int)
```

---

## ‚öôÔ∏è Parameters

| Parameter | Default | Description |
|-----------|---------|-------------|
| `n_estimators` | 100 | Number of boosting iterations |
| `learning_rate` | 0.1 | Step size shrinkage |
| `max_depth` | 6 | Maximum tree depth |
| `max_bins` | 255 | Histogram bins |
| `subsample` | 1.0 | Row sampling ratio |
| `colsample_bytree` | 1.0 | Feature sampling ratio |
| `min_child_weight` | 1.0 | Minimum leaf hessian sum |
| `lambda_l2` | 1.0 | L2 regularization |
| `verbosity` | 1 | Verbosity level (0=silent) |

---

## üìà Detailed Benchmark

```
Performance by category (30 datasets):

IMBALANCED:    TC wins Accuracy 4/4, F1 4/4 | Speedup 1.8x train, 5.7x inference
SYNTHETIC:     TC wins ROC-AUC 3/5         | Speedup 1.3x train, 7.3x inference  
SCALE:         TC wins Accuracy 2/3        | Speedup 5.3x train, 9.5x inference
HIGH-DIM:      TC wins Accuracy 2/4        | Speedup 7.1x train, 17.1x inference
SPECIAL:       TC wins Accuracy 3/4        | Speedup 2.0x train, 15.1x inference
```


<a name="russian"></a>
# üá∑üá∫ –†—É—Å—Å–∫–∏–π

**–ì—Ä–∞–¥–∏–µ–Ω—Ç–Ω—ã–π –±—É—Å—Ç–∏–Ω–≥ –Ω–æ–≤–æ–≥–æ –ø–æ–∫–æ–ª–µ–Ω–∏—è ‚Äî –∫–∞—á–µ—Å—Ç–≤–æ CatBoost, —Å–∫–æ—Ä–æ—Å—Ç—å –≤ 3-10 —Ä–∞–∑ –≤—ã—à–µ.**

TurboCat ‚Äî –±–∏–±–ª–∏–æ—Ç–µ–∫–∞ –≥—Ä–∞–¥–∏–µ–Ω—Ç–Ω–æ–≥–æ –±—É—Å—Ç–∏–Ω–≥–∞ –Ω–∞ C++ —Å Python-–ø—Ä–∏–≤—è–∑–∫–∞–º–∏, —Ä–µ–∞–ª–∏–∑—É—é—â–∞—è —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–µ –∏—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–µ —Ç–µ—Ö–Ω–∏–∫–∏: GradTree (AAAI 2024), Robust Focal Loss, Tsallis entropy splitting, GOSS sampling.

[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

---

## üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –±–µ–Ω—á–º–∞—Ä–∫–æ–≤

–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞ 30 –¥–∞—Ç–∞—Å–µ—Ç–∞—Ö (—Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏–µ, –Ω–µ—Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ, –Ω–µ–ª–∏–Ω–µ–π–Ω—ã–µ, –≤—ã—Å–æ–∫–æ—Ä–∞–∑–º–µ—Ä–Ω—ã–µ, —Ä–µ–∞–ª—å–Ω—ã–µ):

### –ö–∞—á–µ—Å—Ç–≤–æ: –ü–∞—Ä–∏—Ç–µ—Ç —Å CatBoost

| –ú–µ—Ç—Ä–∏–∫–∞ | TurboCat | CatBoost | p-value |
|---------|----------|----------|---------|
| Accuracy | 0.9164 | 0.9171 | 0.87 |
| ROC-AUC | 0.9515 | 0.9568 | 0.17 |
| F1 | **0.8786** | 0.8695 | 0.31 |
| Recall | **0.8657** | 0.8592 | 0.45 |

*–°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏ –∑–Ω–∞—á–∏–º–æ–π —Ä–∞–∑–Ω–∏—Ü—ã –Ω–µ—Ç (t-–∫—Ä–∏—Ç–µ—Ä–∏–π, –∫—Ä–∏—Ç–µ—Ä–∏–π –£–∏–ª–∫–æ–∫—Å–æ–Ω–∞).*

### –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: TurboCat –±—ã—Å—Ç—Ä–µ–µ

| –ú–µ—Ç—Ä–∏–∫–∞ | TurboCat vs CatBoost |
|---------|---------------------|
| –û–±—É—á–µ–Ω–∏–µ | **–≤ 3.5 —Ä–∞–∑–∞ –±—ã—Å—Ç—Ä–µ–µ** (–º–µ–¥–∏–∞–Ω–∞ 1.8x) |
| –ò–Ω—Ñ–µ—Ä–µ–Ω—Å | **–≤ 9.7 —Ä–∞–∑–∞ –±—ã—Å—Ç—Ä–µ–µ** (–º–µ–¥–∏–∞–Ω–∞ 6.8x) |
| –ú–∞–∫—Å–∏–º—É–º | –¥–æ **18.9x** –æ–±—É—á–µ–Ω–∏–µ, **33x** –∏–Ω—Ñ–µ—Ä–µ–Ω—Å |

---

## ‚úÖ –°–∏–ª—å–Ω—ã–µ —Å—Ç–æ—Ä–æ–Ω—ã

### 1. –ù–µ—Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ ‚Äî –≥–ª–∞–≤–Ω–æ–µ –ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–æ

TurboCat –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ –ª—É—á—à–µ –Ω–∞ –Ω–µ—Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö:

| –î–∞—Ç–∞—Å–µ—Ç | Recall TC | Recall CB | F1 TC | F1 CB |
|---------|-----------|-----------|-------|-------|
| 70/30 | **91.2%** | 87.4% | **93.6%** | 91.3% |
| 85/15 | **84.7%** | 75.9% | **89.8%** | 84.7% |
| 95/5 | **54.5%** | 45.5% | **70.2%** | 62.1% |
| 99/1 | **15.8%** | 3.5% | **27.3%** | 6.8% |

–ù–∞ —ç–∫—Å—Ç—Ä–µ–º–∞–ª—å–Ω–æ –Ω–µ—Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö (99/1) TurboCat –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç **F1 –≤ 4 —Ä–∞–∑–∞ –≤—ã—à–µ**.

### 2. –°–∫–æ—Ä–æ—Å—Ç—å

- –û–±—É—á–µ–Ω–∏–µ: –±—ã—Å—Ç—Ä–µ–µ –Ω–∞ 23/30 –¥–∞—Ç–∞—Å–µ—Ç–æ–≤
- –ò–Ω—Ñ–µ—Ä–µ–Ω—Å: –±—ã—Å—Ç—Ä–µ–µ –Ω–∞ 30/30 –¥–∞—Ç–∞—Å–µ—Ç–æ–≤
- –û—Å–æ–±–µ–Ω–Ω–æ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–µ–Ω –Ω–∞ –º–∞–ª—ã—Ö –∏ —Å—Ä–µ–¥–Ω–∏—Ö –¥–∞—Ç–∞—Å–µ—Ç–∞—Ö (–¥–æ 20x —É—Å–∫–æ—Ä–µ–Ω–∏—è)

### 3. –°—Ä–µ–¥–Ω–∏–π –∏ –±–æ–ª—å—à–æ–π –º–∞—Å—à—Ç–∞–± (5K-50K samples)

- Accuracy: 4/5 –ø–æ–±–µ–¥ –Ω–∞–¥ CatBoost
- ROC-AUC: 4/5 –ø–æ–±–µ–¥

### 4. –û—Å–æ–±—ã–µ —Å–ª—É—á–∞–∏

- **–í—ã—Å–æ–∫–æ–∫–æ—Ä—Ä–µ–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏**: +0.2% ROC-AUC
- **–î–∞–Ω–Ω—ã–µ —Å –≤—ã–±—Ä–æ—Å–∞–º–∏**: +0.3% ROC-AUC
- **–í—ã—Å–æ–∫–æ—Ä–∞–∑–º–µ—Ä–Ω—ã–µ —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–º–∏ –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏**: +3.2% ROC-AUC

---

## ‚ö†Ô∏è –°–ª–∞–±—ã–µ —Å—Ç–æ—Ä–æ–Ω—ã

### 1. –®—É–º–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ

–ù–∞ –¥–∞–Ω–Ω—ã—Ö —Å >10% label noise TurboCat –ø—Ä–æ–∏–≥—Ä—ã–≤–∞–µ—Ç –¥–æ -9.9% ROC-AUC.

### 2. –ú–∞–ª–µ–Ω—å–∫–∏–µ –¥–∞—Ç–∞—Å–µ—Ç—ã (<1K samples)

CatBoost –ª—É—á—à–µ –æ–±–æ–±—â–∞–µ—Ç –Ω–∞ –º–∞–ª—ã—Ö –≤—ã–±–æ—Ä–∫–∞—Ö (1/4 –ø–æ–±–µ–¥ –ø–æ ROC-AUC).

### 3. –í—ã—Å–æ–∫–æ—Ä–∞–∑–º–µ—Ä–Ω—ã–µ —Ä–∞–∑—Ä–µ–∂–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ

–ü—Ä–∏ –±–æ–ª—å—à–æ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–µ –Ω–µ—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (200f, 20 informative) CatBoost –Ω–µ–º–Ω–æ–≥–æ –ª—É—á—à–µ.

---

## üéØ –ö–æ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å

### ‚úÖ –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è:

- **Fraud detection, –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∞—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞** ‚Äî –Ω–µ—Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∫–ª–∞—Å—Å—ã
- **Production deployment** ‚Äî –∫—Ä–∏—Ç–∏—á–Ω–∞ —Å–∫–æ—Ä–æ—Å—Ç—å –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞
- **Real-time predictions** ‚Äî –¥–æ 33x –±—ã—Å—Ç—Ä–µ–µ
- **–°—Ä–µ–¥–Ω–∏–µ –∏ –±–æ–ª—å—à–∏–µ –¥–∞—Ç–∞—Å–µ—Ç—ã** ‚Äî 5K+ samples

### ‚ö†Ô∏è –†–∞—Å—Å–º–æ—Ç—Ä–µ—Ç—å –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—ã:

- –û—á–µ–Ω—å —à—É–º–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ (>10% label noise)
- –û—á–µ–Ω—å –º–∞–ª–µ–Ω—å–∫–∏–µ –≤—ã–±–æ—Ä–∫–∏ (<500 samples)
- Extreme high-dimensional sparse data

---

## üõ† –£—Å—Ç–∞–Ω–æ–≤–∫–∞

```bash
git clone https://github.com/ispromadhka/Turbo-Cat.git
cd Turbo-Cat
mkdir build && cd build
cmake .. -DCMAKE_BUILD_TYPE=Release
make -j8
```

### –¢—Ä–µ–±–æ–≤–∞–Ω–∏—è

- C++17 –∫–æ–º–ø–∏–ª—è—Ç–æ—Ä (GCC 10+, Clang 12+, Apple Clang 14+)
- CMake 3.18+
- Python 3.8+
- NumPy

### –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏

- OpenMP (–¥–ª—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è)
- Eigen3 (–∞–≤—Ç–æ-—Å–∫–∞—á–∏–≤–∞–µ—Ç—Å—è –µ—Å–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω)

---

## üî• –ë—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç

```python
import sys
sys.path.insert(0, 'build')
import _turbocat as tc
import numpy as np

# –°–æ–∑–¥–∞–Ω–∏–µ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞
model = tc.TurboCatClassifier(
    n_estimators=50,
    max_depth=8,
    learning_rate=0.1,
    verbosity=0
)

# –û–±—É—á–µ–Ω–∏–µ
model.fit(X_train.astype(np.float32), y_train.astype(np.float32))

# –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
proba = np.array(model.predict_proba(X_test.astype(np.float32)))
predictions = (proba > 0.5).astype(int)
```

---

## ‚öôÔ∏è –ü–∞—Ä–∞–º–µ—Ç—Ä—ã

| –ü–∞—Ä–∞–º–µ—Ç—Ä | –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é | –û–ø–∏—Å–∞–Ω–∏–µ |
|----------|--------------|----------|
| `n_estimators` | 100 | –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–µ—Ä–µ–≤—å–µ–≤ |
| `learning_rate` | 0.1 | –°–∫–æ—Ä–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è |
| `max_depth` | 6 | –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –≥–ª—É–±–∏–Ω–∞ –¥–µ—Ä–µ–≤–∞ |
| `max_bins` | 255 | –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –±–∏–Ω–æ–≤ –≥–∏—Å—Ç–æ–≥—Ä–∞–º–º—ã |
| `subsample` | 1.0 | –î–æ–ª—è —Å—ç–º–ø–ª–æ–≤ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è |
| `colsample_bytree` | 1.0 | –î–æ–ª—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –¥–µ—Ä–µ–≤–∞ |
| `min_child_weight` | 1.0 | –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –≤–µ—Å –ª–∏—Å—Ç–∞ |
| `lambda_l2` | 1.0 | L2 —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è |
| `verbosity` | 1 | –£—Ä–æ–≤–µ–Ω—å –≤—ã–≤–æ–¥–∞ (0=—Ç–∏—Ö–∏–π) |

---

## üìà –î–µ—Ç–∞–ª—å–Ω—ã–π –±–µ–Ω—á–º–∞—Ä–∫

```
–ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º (30 –¥–∞—Ç–∞—Å–µ—Ç–æ–≤):

IMBALANCED:    TC –ø–æ–±–µ–∂–¥–∞–µ—Ç Accuracy 4/4, F1 4/4 | –£—Å–∫–æ—Ä–µ–Ω–∏–µ 1.8x train, 5.7x inference
SYNTHETIC:     TC –ø–æ–±–µ–∂–¥–∞–µ—Ç ROC-AUC 3/5         | –£—Å–∫–æ—Ä–µ–Ω–∏–µ 1.3x train, 7.3x inference  
SCALE:         TC –ø–æ–±–µ–∂–¥–∞–µ—Ç Accuracy 2/3        | –£—Å–∫–æ—Ä–µ–Ω–∏–µ 5.3x train, 9.5x inference
HIGH-DIM:      TC –ø–æ–±–µ–∂–¥–∞–µ—Ç Accuracy 2/4        | –£—Å–∫–æ—Ä–µ–Ω–∏–µ 7.1x train, 17.1x inference
SPECIAL:       TC –ø–æ–±–µ–∂–¥–∞–µ—Ç Accuracy 3/4        | –£—Å–∫–æ—Ä–µ–Ω–∏–µ 2.0x train, 15.1x inference
```

---

MIT License
